{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1c222c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "HIP version: 6.2.41133-dd7f95766\n",
      "Device count: 1\n",
      "Device 0: AMD Radeon RX 6800\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"HIP version:\", torch.version.hip)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device 0:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a6333d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d550cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training dataset: 50000\n",
      "Validation dataset: 5000\n",
      "Test dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "val_size = 5000\n",
    "test_size = len(test_data) - val_size\n",
    "\n",
    "val_data, test_data = random_split(test_data, [val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=16, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "print(f'Training dataset: {len(train_loader.dataset)}')\n",
    "print(f'Validation dataset: {len(val_loader.dataset)}')\n",
    "print(f'Test dataset: {len(test_loader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "900e6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adde20eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c3edc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74a3afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResnet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=None)\n",
    "        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.backbone.maxpool = nn.Identity()\n",
    "        self.backbone.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f8c0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyResnet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b06db798b10>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = NeuralNet().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler(device)\n",
    "\n",
    "num_of_epochs = 75\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_of_epochs)\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4cb49428",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ad2931fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename=\"trained_model.pth\"):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "572934e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = load_checkpoint(net, optimizer, filename=\"trained_model.pth\")\n",
    "#start_epoch = checkpoint + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dfbf532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd77d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (1/75),Train Loss: 2.3244, Val Loss: 1.8535, Val Accuracy: 31.80%\n",
      "Epoch (2/75),Train Loss: 1.9036, Val Loss: 1.6257, Val Accuracy: 39.92%\n",
      "Epoch (3/75),Train Loss: 1.6696, Val Loss: 1.4399, Val Accuracy: 50.22%\n",
      "Epoch (4/75),Train Loss: 1.4397, Val Loss: 1.1981, Val Accuracy: 57.12%\n",
      "Epoch (5/75),Train Loss: 1.2285, Val Loss: 1.0191, Val Accuracy: 64.86%\n",
      "Epoch (6/75),Train Loss: 1.0570, Val Loss: 0.7792, Val Accuracy: 72.20%\n",
      "Epoch (7/75),Train Loss: 0.9294, Val Loss: 1.0551, Val Accuracy: 65.18%\n",
      "Epoch (8/75),Train Loss: 0.8530, Val Loss: 1.3172, Val Accuracy: 62.84%\n",
      "Epoch (9/75),Train Loss: 0.8050, Val Loss: 0.6980, Val Accuracy: 75.78%\n",
      "Epoch (10/75),Train Loss: 0.7652, Val Loss: 0.6643, Val Accuracy: 78.00%\n",
      "Epoch (11/75),Train Loss: 0.7449, Val Loss: 0.6992, Val Accuracy: 76.60%\n",
      "Epoch (12/75),Train Loss: 0.7200, Val Loss: 0.5830, Val Accuracy: 79.66%\n",
      "Epoch (13/75),Train Loss: 0.6998, Val Loss: 0.5458, Val Accuracy: 81.52%\n",
      "Epoch (14/75),Train Loss: 0.6783, Val Loss: 0.7411, Val Accuracy: 74.52%\n",
      "Epoch (15/75),Train Loss: 0.6588, Val Loss: 0.6180, Val Accuracy: 79.76%\n",
      "Epoch (16/75),Train Loss: 0.6471, Val Loss: 0.5447, Val Accuracy: 81.10%\n",
      "Epoch (17/75),Train Loss: 0.6334, Val Loss: 0.5781, Val Accuracy: 80.68%\n",
      "Epoch (18/75),Train Loss: 0.6209, Val Loss: 0.4837, Val Accuracy: 83.28%\n",
      "Epoch (19/75),Train Loss: 0.6126, Val Loss: 0.6646, Val Accuracy: 79.86%\n",
      "Epoch (20/75),Train Loss: 0.6014, Val Loss: 0.5047, Val Accuracy: 83.22%\n",
      "Epoch (21/75),Train Loss: 0.5840, Val Loss: 0.5585, Val Accuracy: 80.86%\n",
      "Epoch (22/75),Train Loss: 0.5805, Val Loss: 0.5811, Val Accuracy: 81.06%\n",
      "Epoch (23/75),Train Loss: 0.5701, Val Loss: 0.5135, Val Accuracy: 82.52%\n",
      "Epoch (24/75),Train Loss: 0.5561, Val Loss: 0.5457, Val Accuracy: 82.28%\n",
      "Epoch (25/75),Train Loss: 0.5434, Val Loss: 0.4860, Val Accuracy: 84.08%\n",
      "Epoch (26/75),Train Loss: 0.5388, Val Loss: 0.5085, Val Accuracy: 82.86%\n",
      "Epoch (27/75),Train Loss: 0.5304, Val Loss: 0.5520, Val Accuracy: 82.36%\n",
      "Epoch (28/75),Train Loss: 0.5250, Val Loss: 0.5647, Val Accuracy: 81.84%\n",
      "Epoch (29/75),Train Loss: 0.5244, Val Loss: 0.4343, Val Accuracy: 85.06%\n",
      "Epoch (30/75),Train Loss: 0.5067, Val Loss: 0.4683, Val Accuracy: 84.76%\n",
      "Epoch (31/75),Train Loss: 0.4951, Val Loss: 0.5525, Val Accuracy: 82.46%\n",
      "Epoch (32/75),Train Loss: 0.4860, Val Loss: 0.4445, Val Accuracy: 85.20%\n",
      "Epoch (33/75),Train Loss: 0.4902, Val Loss: 0.3577, Val Accuracy: 87.82%\n",
      "Epoch (34/75),Train Loss: 0.4712, Val Loss: 0.4112, Val Accuracy: 86.16%\n",
      "Epoch (35/75),Train Loss: 0.4589, Val Loss: 0.3810, Val Accuracy: 86.86%\n",
      "Epoch (36/75),Train Loss: 0.4500, Val Loss: 0.4487, Val Accuracy: 85.26%\n",
      "Epoch (37/75),Train Loss: 0.4430, Val Loss: 0.3739, Val Accuracy: 87.20%\n",
      "Epoch (38/75),Train Loss: 0.4365, Val Loss: 0.3616, Val Accuracy: 87.80%\n",
      "Epoch (39/75),Train Loss: 0.4253, Val Loss: 0.4149, Val Accuracy: 87.00%\n",
      "Epoch (40/75),Train Loss: 0.4205, Val Loss: 0.3378, Val Accuracy: 88.94%\n",
      "Epoch (41/75),Train Loss: 0.4087, Val Loss: 0.3798, Val Accuracy: 87.32%\n",
      "Epoch (42/75),Train Loss: 0.3943, Val Loss: 0.3455, Val Accuracy: 88.20%\n",
      "Epoch (43/75),Train Loss: 0.3889, Val Loss: 0.3555, Val Accuracy: 88.84%\n",
      "Epoch (44/75),Train Loss: 0.3877, Val Loss: 0.3282, Val Accuracy: 89.44%\n",
      "Epoch (45/75),Train Loss: 0.3695, Val Loss: 0.3266, Val Accuracy: 89.58%\n",
      "Epoch (46/75),Train Loss: 0.3597, Val Loss: 0.3104, Val Accuracy: 89.86%\n",
      "Epoch (47/75),Train Loss: 0.3491, Val Loss: 0.2695, Val Accuracy: 90.62%\n",
      "Epoch (48/75),Train Loss: 0.3411, Val Loss: 0.2900, Val Accuracy: 90.30%\n",
      "Epoch (49/75),Train Loss: 0.3280, Val Loss: 0.3270, Val Accuracy: 89.58%\n",
      "Epoch (50/75),Train Loss: 0.3212, Val Loss: 0.2849, Val Accuracy: 90.16%\n",
      "Epoch (51/75),Train Loss: 0.3064, Val Loss: 0.3638, Val Accuracy: 88.30%\n",
      "Epoch (52/75),Train Loss: 0.2933, Val Loss: 0.2590, Val Accuracy: 91.62%\n",
      "Epoch (53/75),Train Loss: 0.2874, Val Loss: 0.2536, Val Accuracy: 91.74%\n",
      "Epoch (54/75),Train Loss: 0.2730, Val Loss: 0.2629, Val Accuracy: 91.16%\n",
      "Epoch (55/75),Train Loss: 0.2613, Val Loss: 0.2483, Val Accuracy: 91.58%\n",
      "Epoch (56/75),Train Loss: 0.2485, Val Loss: 0.2275, Val Accuracy: 92.54%\n",
      "Epoch (57/75),Train Loss: 0.2423, Val Loss: 0.2233, Val Accuracy: 92.60%\n",
      "Epoch (58/75),Train Loss: 0.2259, Val Loss: 0.2219, Val Accuracy: 92.70%\n",
      "Epoch (59/75),Train Loss: 0.2163, Val Loss: 0.2230, Val Accuracy: 92.90%\n",
      "Epoch (60/75),Train Loss: 0.2029, Val Loss: 0.2377, Val Accuracy: 92.70%\n",
      "Epoch (61/75),Train Loss: 0.1929, Val Loss: 0.2072, Val Accuracy: 93.32%\n",
      "Epoch (62/75),Train Loss: 0.1878, Val Loss: 0.1904, Val Accuracy: 93.80%\n",
      "Epoch (63/75),Train Loss: 0.1726, Val Loss: 0.2053, Val Accuracy: 93.66%\n",
      "Epoch (64/75),Train Loss: 0.1599, Val Loss: 0.1965, Val Accuracy: 94.24%\n",
      "Epoch (65/75),Train Loss: 0.1514, Val Loss: 0.1924, Val Accuracy: 94.12%\n",
      "Epoch (66/75),Train Loss: 0.1436, Val Loss: 0.1804, Val Accuracy: 94.18%\n",
      "Epoch (67/75),Train Loss: 0.1329, Val Loss: 0.1788, Val Accuracy: 94.58%\n",
      "Epoch (68/75),Train Loss: 0.1333, Val Loss: 0.1793, Val Accuracy: 94.60%\n",
      "Epoch (69/75),Train Loss: 0.1216, Val Loss: 0.1773, Val Accuracy: 94.54%\n",
      "Epoch (70/75),Train Loss: 0.1198, Val Loss: 0.1625, Val Accuracy: 95.04%\n",
      "Epoch (71/75),Train Loss: 0.1200, Val Loss: 0.1651, Val Accuracy: 94.84%\n",
      "Epoch (72/75),Train Loss: 0.1165, Val Loss: 0.1655, Val Accuracy: 95.00%\n",
      "Epoch (73/75),Train Loss: 0.1120, Val Loss: 0.1641, Val Accuracy: 94.94%\n",
      "Epoch (74/75),Train Loss: 0.1088, Val Loss: 0.1646, Val Accuracy: 94.84%\n",
      "Epoch (75/75),Train Loss: 0.1103, Val Loss: 0.1648, Val Accuracy: 95.00%\n",
      "Highest Validation Accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "highest_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(start_epoch, num_of_epochs):\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for _, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    if val_accuracy > highest_val_accuracy:\n",
    "        highest_val_accuracy = val_accuracy\n",
    "\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": net.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict(),\n",
    "            \"scaler_state\": scaler.state_dict(),\n",
    "            \"config\": {\n",
    "                \"conv1_kernel\": 3,\n",
    "                \"remove_maxpool\": True,\n",
    "                \"num_classes\": 10\n",
    "            },\n",
    "            \"best_val_accuracy\": highest_val_accuracy\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, \"trained_model.pth\")\n",
    "    \n",
    "    global_step = epoch + 1\n",
    "    writer.add_scalar(\"Loss/Train\", avg_train_loss, global_step)\n",
    "    writer.add_scalar(\"Loss/Val\", avg_val_loss, global_step)\n",
    "    writer.add_scalar(\"Accuracy/Val\", val_accuracy, global_step)\n",
    "    writer.add_scalar(\"Params/LR\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "\n",
    "    print(\n",
    "        f'Epoch ({epoch + 1}/{num_of_epochs}),'\n",
    "        f'Train Loss: {avg_train_loss:.4f}, '\n",
    "        f'Val Loss: {avg_val_loss:.4f}, '\n",
    "        f'Val Accuracy: {val_accuracy:.2f}%'\n",
    "        )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "writer.flush()\n",
    "\n",
    "print(f'Highest Validation Accuracy: {highest_val_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
